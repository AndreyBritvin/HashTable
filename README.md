# Оптимизация Хэш-Таблицы

## Введение
Хэш-таблица - способ хранения данных с временем поиска элемента `O(1)` за счёт использования хэш-функций. Из-за неидеальности хэш-функций, разным входным данным может соответствовать одинаковый хэш. Такая ситуация называется коллизией. Существуют разные способы разрешения коллизий, например, метод открытой адресации или же метод цепочек, который и используется в данной работе.

Данные хранятся в бакетах (buckets), каждый из которых представляет из себя список. Количество бакетов это размер хэш-таблицы. Число элементов / размер хэш таблицы = Load-factor. Оптимальный load-factor находится между 1 и 2, но в данной работе он был искусственно повышен до 15, чтобы увеличить время поиска элемента.

Для поиска считается хэш входных данных, берётся остаток от деления на размер таблицы и получается номер бакета, в котором содержится наш элемент. Поскольку могут происходить коллизии, или же размер таблицы достаточно маленький, то в одном бакете будет содержаться несколько элементов. Но их количество гораздо меньше в сравнении со всем объёмом данных, так что дальше делается обычный линейный поиск.

В данной работе для заполнения таблицы использовался текст Л.Н.Толстого ["Война и мир"](txt_parser/war_and_peace.txt) на английском языке (около 600к слов всего, ~25к слов уникальных), предварительно обработанный [python-скриптом](txt_parser/parser.py) для разделения файла на строки и удаления большинства ненужных символов

## Цели и задачи
### Цель
Оптимизация поиска в хэш-таблице различными методами
### Задачи
- Исследовать различные хэш-функции на максимально количество коллизий
- Написать базовую версию хэш-таблицы
- Подготовить текст для заполнения
- Найти узкие места в программе (в функции поиска в таблице) и оптимизировать их, используя как минимум три метода (акцентируясь на аппаратно-зависимых методах оптимизации):
    * Ассемблерная вставка
    * Использование интринсиков
    * Использование функции, написанной в отдельном ассемблерном файле

## Исследование хэш-функций

Для максимальной эффективности работы хэш-таблицы требуется хэш функция, с наименьшим числом коллизий, то есть распределяющая все данные равномерно. Для этого рассмотрим распределения слов по таблице в зависимости от хэш-функции

### Нулевой хэш
![zero-hash](txt_parser/hash_distr/zero_hash.png)
Несмотря на запрет семинариста по матанализу говорить слово очевидно... Тут и так всё ясно - хэш таблица превратилась в обычный линейный список и никакого ускорения тут не получается

Максимальная коллизия `24330`

### Длина слова
Казалось бы, должно быть более равномерно, но всё равно в силу статистики русского языка часто встречаются слова 5-6 букв, а количство слов другой длины претерпевает резкое падение.

![length-hash](txt_parser/hash_distr/length_hash.png)

Максимальная коллизия `3716`

### Сумма ASCII-кодов
Тут уже не столь тривиально, ведь ascii помимо длины слова каждая буква имеет вес. Поэтому распределение получилось более равномерным, однако всё равно талица заполнена не полностью и количество коллизиий весьма высоко
![sum-ascii-hash](txt_parser/hash_distr/sum_ascii_hash.png)

Максимальная коллизия `105`

### CRC32
Математически обоснованный равномерный хэш. Достаточно прост в реализации, даёт равномерное распределние по всей длине таблицы. Всё чики-бамбони.
![crc32-hash](txt_parser/hash_distr/crc32_hash.png)

Максимальная коллизия `7`

### SHA256
Сложно было ожидать другого результата от алгоритма, на котором держится вся современная передача данных

![sha256-hash](txt_parser/hash_distr/sha256_distr.png)

Максимальная коллизия `6`

В силу нетривиальности реализации данного алгоритма, остановимся на crc32.

## Поиск оптимизаций
Сначала заполняется вся хэш-таблица, при этом каждому слову ставится в соответствие число, которое показывает, сколько раз это слово встретилось в тексте.

Затем идёт поиск - то что и замеряется в данном проекте. Вызывается фнукция поиска на 100к слов, берётся каждое четвертое слово.

Измерение времени аналогично предыдущему [проекту](github.com/AndreyBritvin/Mandelbrot)

### -O0
Для начала запустим базовую версию с -O0, как версию, которая компилируется по умолчанию, и замерим время одной инструкции

| Среднее кол-во тактов на одно слово | Погрешность, такты |
|-------------------------------------|-------------------|
| 535                                 | +-12              |

### -O3
Далее включим максимальную оптимизацию и посмотрим, насколько компилятор сможет ускорить поиск

| Среднее кол-во тактов на одно слово | Пошреность, такты | Ускорение отн. предыдущего |
|-------------------------------------|-------------------|----------------------------|
| 190                                 | +-10              | 180%                       |

### Изменение хэш-функции (интринсик)
Найдя самую горячую функции становится очевидно, что надо делать!
![До crc32](img/only_o3_2.png)

Надо всего лишь переписать crc32 с использованием интринсика _mm_crc32_u8

Результат:
![Реузльтат crc32](img/crc32_intr_3.png)
| Среднее кол-во тактов на одно слово | Пошреность, такты | Ускорение отн. предыдущего |
|-------------------------------------|-------------------|----------------------------|
| 105                                 | +-7               | 80%                        |

### Интринсики: strcmp
![Картинка](img/strcmp_finding.png)

```
134:    while (NEXT[previous_next] != NEXT[0])
        {
137:        if (!strcmp(text, DATA[previous_next].word))
            {
                return &DATA[previous_next];
            }

            previous_next = NEXT[previous_next];
        }
```
Зная, что в тексте не встречаются слова длиной больше 32 букв (проверено при помощи [скрипта](txt_parser/find_max_len.py)), можно оптмиизировать strcmp, который вызывается внутри поиска по списку. Оптимизация заключается в использовании `YMM` регистров и последующем сравнении двух строк при помощи интринсиков на сравнение двух AVX-регистров.

Вот получившаяся функция:

~~~
int my_avx_strcmp(const char* str1, const char* str2)
{
    __m256i string_1 = _mm256_loadu_si256((__m256i *) str1);
    __m256i string_2 = _mm256_loadu_si256((__m256i *) str2);
    __m256i equal    = _mm256_cmpeq_epi64(string_1, string_2);
    int result = _mm256_movemask_epi8(equal);

    return ~result;
}
~~~

Но данный метод оптимизации накладывает следущие ограничения:
- Поддерживаемые слова меньше 32 символов
- В исходном представлении в памяти на каждое слово также должно отводиться по 32 байта, чтобы могло быстро выполниться __m256_loadu, следовательно, перерасход памяти.

| Среднее кол-во тактов на одно слово | Пошреность, такты | Ускорение отн. предыдущего |
|-------------------------------------|-------------------|----------------------------|
| 101                                 | +-8               | 4%                         |

### Остаток от деления - ассемблерная вставка
Графики perf и hotspot больше не показывают на новые медленные места - всё что можно, уже оптимизировано. Однако по заданию надо сделать ещё два вида оптимизаций.
![Делать нечего](img/before_asm_inline.png)

Поэтому я выбрал строчку для ассемблерной вставки с остатком от деления по модулю, чтобы взять частный случай размера таблицы `2^N`, таким образом заменив `div` на `&`. Получилась такая вставка:
```
asm volatile(
    "and %2, %1\n"              // instruction
    : "=r" (bucket_num)         // output
    : "r"  ((size_t) hash),     // input
      "r"  (ht->size - 1)
    );
```

Поскольку теперь размер хэш таблицы должен быть степенью двойки, то придётся его поменять на 2^15, как наиболее близкое число, которое оставляет load-factor на высоком уровнем (около 15)

Предварительно измерив тесты без ассемблерной вставки с изменненым размером таблицы, ожидаемо, не повлияло на среднее время поиска слова в таблице.

Затем измерив время с вставкой получим результат в таблице. Perf вообще перестал показывать данную строку.

![Результат](img/after_asm_inline_2.png)

Ограничения:
* Размер таблицы должен быть 2^n

| Среднее кол-во тактов на одно слово | Пошреность, такты | Ускорение отн. предыдущего |
|-------------------------------------|-------------------|----------------------------|
| 96                                  | +-5               | 5%                         |

### Ассемблеровский файл. Назад к истокам
У нас всё ещё осталась необходимость в использовании оптимизации при помощи использования отдельного ассемблерного файла. Одна из самых горячих функций, которая до сих пор не использует ограничения, внесенные другими оптимизациями (ограниченная длина слова) - это функция расчёта хэша. Теперь вместо универсального использования параметра length, который компилятор не может оптимизировать, мы можем использовать jump-таблицу по возможным значениям параметра длины слова

Это существенно ускорит код из-за мнгновенного, в сравнении с условным переходом в цикле, перехода кода. Правда, в моей реализации получился инвертированный crc32, считающий хэш слова в обратном порядке, так что такой алгоритм не подойдет для связки с внешними системами, зато код быстро выполняется и легко читается.

| Среднее кол-во тактов на одно слово | Пошреность, такты | Ускорение отн. предыдущего |
|-------------------------------------|-------------------|----------------------------|
| 90                                  | +-5               | 6%                         |

### Что же дальше?
 Хотя в современном реалиях борются за каждые десятые процента ускорения, в то время как я остановился на ускорении порядка 1%, на этом я вынужден завершить оптимизации и перейти к выводам

## В завершение
Результаты всех тестов можно найти в [файле](Results.xlsx)

Итоговая таблица:
|                                     | -O0 | -O3  | Хэш-интринсик | Strcmp-интринсик | Mod через ассемблеревскую вставку | Хэш через файл |
|-------------------------------------|-----|------|---------------|------------------|-----------------------------------|----------------|
| Среднее кол-во тактов на одно слово | 535 | 190  | 105           | 101              | 95                                | 90             |
| Ускорение отн. предыдущего          |     | 182% | 80%           | 4%               | 5%                                | 6%             |

Суммарное ускорение относительно `-O3` составило `95%`.
В работе было исследованы и реализованы различные методы оптимизации, их положительные и отрицательные стороны, которые стоит отдельно отметить:
* Аппаратно-зависимый код (использование интринсиков на `YMM` регистрах)
* Ограничение максимальной длины слова (32 буквы)
* Потеря читаемости кода
* Таблица должна быть размером `2^n`
* Каждое слово должно быть выровнено по 32 байта

Из положительных сторон:
* Ускорение работы кода

Стоило ли оно того? В таком маленьком проекте ещё может быть да, но в более крупных проектах необходимо более тщательно и основательно продумывать метод оптимизации и его реализацию.
